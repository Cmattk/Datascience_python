{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703c5a93-0f37-4718-b4ab-339dcc60a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFeature Scaling is a technique to standardize the independent features present in the data.\\nIt is performed during the data pre-processing to handle highly varying values.\\nIf feature scaling is not done then machine learning algorithm tends to use greater values as higher and\\nconsider smaller values as lower regardless of the unit of the values.\\nFor example it will take 10 m and 10 cm both as same regardless of their unit.\\nWe will learn about different techniques which are used to perform feature scaling.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature Scaling is a technique to standardize the independent features present in the data.\n",
    "It is performed during the data pre-processing to handle highly varying values.\n",
    "If feature scaling is not done then machine learning algorithm tends to use greater values as higher and\n",
    "consider smaller values as lower regardless of the unit of the values.\n",
    "For example it will take 10 m and 10 cm both as same regardless of their unit.\n",
    "We will learn about different techniques which are used to perform feature scaling.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de12f76a-b893-49b1-b5b5-4d6daaf54668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotArea  MSSubClass\n",
      "0     8450          60\n",
      "1     9600          20\n",
      "2    11250          60\n",
      "3     9550          70\n",
      "4    14260          60\n",
      "LotArea       215245\n",
      "MSSubClass       190\n",
      "dtype: int64\n",
      "    LotArea  MSSubClass\n",
      "0 -0.960742   -0.684211\n",
      "1 -0.955400   -0.894737\n",
      "2 -0.947734   -0.684211\n",
      "3 -0.955632   -0.631579\n",
      "4 -0.933750   -0.684211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Absolute Maximum Scaling\n",
    "1. We should first select the maximum absolute value out of all the entries of a particular measure.\n",
    "2. Then after this we divide each entry of the column by this maximum value.\n",
    "Xscaled = Xi-max(∣X∣)/max(∣X∣)\n",
    "\n",
    "this method is not used that often the reason behind this is that it is too sensitive to the outliers\n",
    "each entry of the column lies in the range of -1 to 1\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('downloads/SampleFile.csv')\n",
    "print(df.head())\n",
    "\n",
    "max_vals = df.abs().max()\n",
    "print(max_vals)\n",
    "df_scaled = (df - max_vals) / max_vals\n",
    "print(df_scaled.head())\n",
    "type(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5294911d-8700-47f6-bfdb-012f59bbf7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MSSubClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  MSSubClass\n",
       "0  0.033420    0.235294\n",
       "1  0.038795    0.000000\n",
       "2  0.046507    0.235294\n",
       "3  0.038561    0.294118\n",
       "4  0.060576    0.235294"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  \n",
    "Min-Max Scaling\n",
    "1. First we are supposed to find the minimum and the maximum value of the column.\n",
    "2. Then we will subtract the minimum value from the entry and\n",
    "   divide the result by the difference between the maximum and the minimum value.\n",
    "X_scaled = Xi - Xmin / Xmax-Xmin\n",
    "this method is also prone to outliers but the range in which the data will range \n",
    "between 0 to 1, after performing the above two steps.\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(scaled_data,columns=df.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60010067-9d24-4d75-81e5-03968d7df1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LotArea  MSSubClass\n",
      "0  0.999975    0.007100\n",
      "1  0.999998    0.002083\n",
      "2  0.999986    0.005333\n",
      "3  0.999973    0.007330\n",
      "4  0.999991    0.004208\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. Normalization\n",
    "we subtract each entry by the mean value of the whole data and\n",
    "then divide the results by the difference between the minimum and the maximum value.\n",
    "X_scaled = Xi-Xmean / Xmax-Xmin\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "083af1e7-87cd-4bb1-a656-b7542502c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LotArea  MSSubClass\n",
      "0 -0.207142    0.073375\n",
      "1 -0.091886   -0.872563\n",
      "2  0.073480    0.073375\n",
      "3 -0.096897    0.309859\n",
      "4  0.375148    0.073375\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. Standardization\n",
    "This method of scaling is basically based on the central tendencies and variance of the data. \n",
    "1. Calculate the mean and standard deviation of the data we would like to normalize it.\n",
    "2. Then we are supposed to subtract the mean value from each entry and\n",
    "   then divide the result by the standard deviation.\n",
    "(This helps us achieve a normal distribution of the data with a mean equal to zero and a standard deviation equal to 1.)\n",
    "X_scaled = Xi - Xmean/sd\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data,columns=df.columns)\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b51744f6-ae6a-47c1-92ab-c68bd63e50a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LotArea  MSSubClass\n",
      "0 -0.254076         0.2\n",
      "1  0.030015        -0.6\n",
      "2  0.437624         0.2\n",
      "3  0.017663         0.4\n",
      "4  1.181201         0.2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. Robust Scaling\n",
    "In this method of scaling, we use two main statistical measures of the data.\n",
    "Median\n",
    "Inter-Quartile Range\n",
    "After calculating these two values we are supposed to subtract the median from each entry\n",
    "and then divide the result by the interquartile range.\n",
    "X_scaled = Xi - Xmedian / IQR\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data,columns=df.columns)\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a01a07fe-e064-4004-9b9b-7b0b63a88c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy use Feature Scaling?\\nIn machine learning feature scaling is used for number of purposes:\\n\\nRange: \\n    Scaling guarantees that all features are on a comparable scale and have comparable ranges. \\n    This process is known as feature normalisation.\\n    This is significant because the magnitude of the features has an impact on many machine learning techniques. \\n    Larger scale features may dominate the learning process and have an excessive impact on the outcomes.\\nAlgorithm performance improvement: \\n    When the features are scaled several machine learning methods including\\n    gradient descent-based algorithms, distance-based algorithms (such k-nearest neighbours) and\\n    support vector machines perform better or converge more quickly. \\n    The algorithm’s performance can be enhanced by scaling the features which prevent the convergence of the algorithm to the ideal outcome.\\nPreventing numerical instability: \\n    Numerical instability can be prevented by avoiding significant scale disparities between features.\\n    For examples include distance calculations where having features with differing scales can result in numerical overflow or underflow problems. \\n    Stable computations are required to mitigate this issue by scaling the features.\\nEqual importance: \\n    Scaling features makes sure that each characteristic is given the same consideration during the learning process. \\n    Without scaling bigger scale features could dominate the learning producing skewed outcomes. \\n    This bias is removed through scaling and each feature contributes fairly to model predictions.\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scaling, normalization and standardization are essential feature engineering techniques that ensure data is well-prepared for machine learning models.\n",
    "They help improve model performance, enhance convergence and reduce biases.\n",
    "Choosing the right method depends on your data and algorithm\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Why use Feature Scaling?\n",
    "In machine learning feature scaling is used for number of purposes:\n",
    "\n",
    "Range: \n",
    "    Scaling guarantees that all features are on a comparable scale and have comparable ranges. \n",
    "    This process is known as feature normalisation.\n",
    "    This is significant because the magnitude of the features has an impact on many machine learning techniques. \n",
    "    Larger scale features may dominate the learning process and have an excessive impact on the outcomes.\n",
    "Algorithm performance improvement: \n",
    "    When the features are scaled several machine learning methods including\n",
    "    gradient descent-based algorithms, distance-based algorithms (such k-nearest neighbours) and\n",
    "    support vector machines perform better or converge more quickly. \n",
    "    The algorithm’s performance can be enhanced by scaling the features which prevent the convergence of the algorithm to the ideal outcome.\n",
    "Preventing numerical instability: \n",
    "    Numerical instability can be prevented by avoiding significant scale disparities between features.\n",
    "    For examples include distance calculations where having features with differing scales can result in numerical overflow or underflow problems. \n",
    "    Stable computations are required to mitigate this issue by scaling the features.\n",
    "Equal importance: \n",
    "    Scaling features makes sure that each characteristic is given the same consideration during the learning process. \n",
    "    Without scaling bigger scale features could dominate the learning producing skewed outcomes. \n",
    "    This bias is removed through scaling and each feature contributes fairly to model predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5572425-7d8b-4b2f-a993-cb821b13c1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8edce1-ea78-44b7-8f16-88df0c566df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
